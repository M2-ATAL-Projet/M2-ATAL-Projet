{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4ae8f9",
      "metadata": {
        "id": "3c4ae8f9"
      },
      "outputs": [],
      "source": [
        "%pip install accelerate evaluate numpy transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8c64ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import ClassLabel, Features, load_dataset, TextClassification, Value\n",
        "from os import sched_getaffinity\n",
        "from torch import get_num_threads, set_num_threads\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
        "\n",
        "import evaluate\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aa48eab",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_threads = max(1, get_num_threads(), len(sched_getaffinity(0)) - 1)\n",
        "set_num_threads(num_threads)\n",
        "num_threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b4b723",
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_groups = ['Criminal', 'Tax']\n",
        "labels = ['PREAMBLE', 'FAC', 'RLC', 'ISSUE', 'ARG_PETITIONER', 'ARG_RESPONDENT', 'ANALYSIS', 'STA', 'PRE_RELIED', 'PRE_NOT_RELIED', 'RATIO', 'RPC', 'NONE']\n",
        "\n",
        "dataset = load_dataset('csv', data_files={\n",
        "    'train': 'BUILD/train.csv',\n",
        "    'test': 'BUILD/dev.csv',\n",
        "}, features=Features({\n",
        "    'doc_id': Value('uint32'),\n",
        "    'doc_index': Value('uint16'),\n",
        "    'sentence_index': Value('uint16'),\n",
        "    'annotation_id': Value('string'),\n",
        "    'text': Value('string'),\n",
        "    'meta_group': ClassLabel(names=meta_groups),\n",
        "    'labels': ClassLabel(names=labels),\n",
        "}), task=TextClassification())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bd0b8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", num_labels=len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7193fddc",
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(lambda t: tokenizer(t['text'], truncation=True), batched=True)\n",
        "tokenized_dataset = tokenized_dataset.remove_columns('text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b021225",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59577d02",
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, references = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=references)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09837d7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_legalbert_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=1,\n",
        "    save_strategy=\"epoch\",\n",
        "    label_names=labels,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "#trained_dataset = tokenized_dataset['train'].train_test_split(test_size=0.2, stratify_by_column='labels')\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['train'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
