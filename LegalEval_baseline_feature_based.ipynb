{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ae8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn nltk numpy pandas spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783b712-422b-43c7-9c3f-33e83d8511e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14558d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a4ae3-919e-455a-827d-769c709bd74e",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f7e9e-3d9b-4033-be4f-17c59001bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('BUILD/train.csv')\n",
    "dev = pd.read_csv('BUILD/dev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff3a15-4b23-4aff-a26a-81502588afe0",
   "metadata": {},
   "source": [
    "## Extraction des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c32d1e-47df-48d8-955c-48178de7769c",
   "metadata": {},
   "source": [
    "Le ColumnTransformer permet de calculer des descripteurs simplement à partir d'un dataframe.\n",
    "Il s'agit d'une liste de 3 élements:\n",
    "- le nom du descripteur (str)\n",
    "- une fonction ou un objet scikit-learn qui implémente `fit` et ou `transform`\n",
    "- la colonne à utiliser\n",
    "\n",
    "Par exemple pour le descripteur `sentence_position`, on va utiliser la colonne `sentence_percent` directement (`passthrough`) (il faut utiliser des crochets pour que la taille du vecteur soit correcte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f258c0c1-3048-4683-b46d-263e0810b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_position(df: pd.DataFrame):\n",
    "    doc2nbsent = df.groupby('doc_id')['sentence_index'].max().to_dict()\n",
    "    df['nb_sent'] = df['doc_id'].map(doc2nbsent.get)\n",
    "    position = df['sentence_index'] / df['nb_sent']\n",
    "    return position.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e966b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_verb(tag: str):\n",
    "    return tag.startswith('VB') or tag == 'MD'\n",
    "\n",
    "def verb_tense(sentence: str):\n",
    "    verbs = [tag for _, tag in nltk.pos_tag(nltk.word_tokenize(sentence)) if is_verb(tag)]\n",
    "    return '' if len(verbs) == 0 else verbs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev['verb_tense'] = dev['text'].map(verb_tense)\n",
    "train['verb_tense'] = train['text'].map(verb_tense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_tense_encoding = ['VB', 'VBC', 'VBD', 'VBF', 'VBG', 'VBN', 'VBP', 'VBZ', 'MD']\n",
    "\n",
    "def verb_tense_encode(df: pd.DataFrame):\n",
    "    return np.asarray([[1 if verb_tense_encoding[i] == vt else 0 for i in range(len(verb_tense_encoding))] for vt in df['verb_tense']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_length(df: pd.DataFrame):\n",
    "    \"\"\"Donne la longueur des phrases.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Corpus\n",
    "    \"\"\"\n",
    "    return df['text'].map(lambda x: len(x.split())).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a526175-92b9-4c29-a40d-d731e4bec04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_ldots(sentence: str):\n",
    "    return 1 if '...' in sentence else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f13059-3037-4f21-a307-bc200f8e3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev['contains_ldots'] = dev['text'].map(contains_ldots)\n",
    "train['contains_ldots'] = train['text'].map(contains_ldots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d28f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.LancasterStemmer()\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super().build_analyzer()\n",
    "        return lambda doc: [stemmer.stem(w) for w in analyzer(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class LemmatizedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super().build_analyzer()\n",
    "        return lambda doc: [nlp(w)[0].lemma_ for w in analyzer(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc185f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super().build_analyzer()\n",
    "        return lambda doc: [w + '/' + tag for w, tag in nltk.pos_tag(analyzer(doc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc1730-c5d3-4471-b2e9-865db82ded17",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        #(\n",
    "        #    TfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=10),\n",
    "        #    'text'\n",
    "        #),\n",
    "        # ==> n'améliore pas\n",
    "        #(\n",
    "        #    StemmedTfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=10),\n",
    "        #    'text'\n",
    "        #),\n",
    "        (\n",
    "            LemmatizedTfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=10),\n",
    "            'text'\n",
    "        ),\n",
    "        # ==> n'améliore pas\n",
    "        #(\n",
    "        #    PosTfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=10),\n",
    "        #    'text'\n",
    "        #),\n",
    "        # ==> n'améliore pas\n",
    "        #(\n",
    "        #    'passthrough',\n",
    "        #    ['sentence_index']\n",
    "        #),\n",
    "        (\n",
    "            'passthrough',\n",
    "            ['contains_ldots']\n",
    "        ),\n",
    "        (\n",
    "            FunctionTransformer(sentence_position),\n",
    "            ['doc_id', 'sentence_index']\n",
    "        ),\n",
    "        # ==> n'améliore pas\n",
    "        #(\n",
    "        #    FunctionTransformer(lambda df: (sentence_position(df) * 100).round()),\n",
    "        #    ['doc_id', 'sentence_index']\n",
    "        #),\n",
    "        # ==> n'améliore pas\n",
    "        #(\n",
    "        #    FunctionTransformer(verb_tense_encode),\n",
    "        #    ['verb_tense']\n",
    "        #),\n",
    "        # ==> trop lent, pas d'impact significatif\n",
    "        #(\n",
    "        #    FunctionTransformer(sentence_length),\n",
    "        #    ['text']\n",
    "        #),\n",
    "    ),\n",
    "    LogisticRegression(multi_class='multinomial', max_iter=10000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c228838-b817-4a64-8fd4-21c0f01f0f4f",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85527abe-b1dc-4feb-9488-4cecd0140049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On entraîne le modèle sur les 100 premiers exemples.\n",
    "classifier.fit(train, train['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80370160-4093-458a-ac11-0fc2f29cae89",
   "metadata": {},
   "source": [
    "## Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a23dbf-e639-462c-bf45-dbba06be5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédit puis choisis l'étiquette qui a la plus haut probabilité\n",
    "dev['pred'] = classifier.predict(dev)\n",
    "train['pred'] = classifier.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9faa92-524e-45c0-9c26-32b5d0187db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour obtenir le nom des étiquettes prédites\n",
    "# On récupère le nom et l'ordre des étiquettes\n",
    "index2label: np.ndarray = classifier.named_steps['logisticregression'].classes_\n",
    "\n",
    "# Retourne la probabilité pour chacune des étiquettes\n",
    "predictions_prob = classifier.predict_proba(dev.iloc[:10])\n",
    "# On choisis l'étiquette avec la plus haute probabilité\n",
    "index_max_predictions = predictions_prob.argmax(axis=1).tolist()\n",
    "\n",
    "# Ces deux liste devraient être les mêmes\n",
    "print([index2label[l] for l in index_max_predictions])\n",
    "print(classifier.predict(dev.iloc[:10]).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3bd76-c5f6-4bf5-b269-f19429c91730",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec1009-6d78-435b-888e-faf4ab335034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aca284-4c7c-4fdf-89dd-5f4b2c520e8c",
   "metadata": {},
   "source": [
    "### Erreur d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e90ab6-d408-4143-9eec-972e648c8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels = train['labels']\n",
    "submission_labels = train['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055409d5-e59f-45ab-b8bf-fddaf265fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    ground_truth_labels, submission_labels, average='weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6536f64a-23b1-4a5d-8b39-9a140d3be58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyformat.info/#number\n",
    "print(f'{precision:.2f}, {recall:.2f}, {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de33fab1-93d8-4f47-8d1e-f11eb5548c7b",
   "metadata": {},
   "source": [
    "### Erreur de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d31c0-4603-4580-96a5-b8edbabad1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels = dev['labels']\n",
    "submission_labels = dev['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1bbfba-868f-4741-8c9d-54a41597d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    ground_truth_labels, submission_labels, average='weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eac2f30-1afb-4768-91f0-0a73f610ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyformat.info/#number\n",
    "print(f'{precision:.2f}, {recall:.2f}, {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d4825",
   "metadata": {},
   "source": [
    "#### Comment évoluent les scores lorsqu'on enlève un descripteur ?\n",
    "\n",
    "| CV | SV | SP | P    | R    | f1   |\n",
    "|----|----|----|------|------|------|\n",
    "| x  | x  | x  | 0.63 | 0.64 | 0.62 |\n",
    "| x  |    | x  | 0.63 | 0.64 | 0.61 |\n",
    "| x  | x  |    | 0.54 | 0.54 | 0.52 |\n",
    "| x  |    |    | 0.54 | 0.54 | 0.52 |\n",
    "|    | x  | x  | 0.38 | 0.54 | 0.44 |\n",
    "|    |    | x  | 0.38 | 0.53 | 0.43 |\n",
    "|    | x  |    | 0.21 | 0.34 | 0.19 |\n",
    "\n",
    "__Observations :__\n",
    "\n",
    "* Les colonnes du *count-vectorizer* (CV) ont le plus d'impact sur le modèle.\n",
    "* La colonne de *single-values* (SV) n'a qu'un très faible impact sur le modèle.\n",
    "\n",
    "#### Comment évoluent les scores lorsqu'on change les paramètres du CountVectorizer ?\n",
    "\n",
    "| `CountVectorizer(...)`                               | P    | R    | f1   |\n",
    "|------------------------------------------------------|------|------|------|\n",
    "| `stop_words='english', ngram_range=(1,3), min_df=10` | 0.63 | 0.64 | 0.62 |\n",
    "| `stop_words='english', ngram_range=(1,8), min_df=10` | 0.64 | 0.64 | 0.62 |\n",
    "| `stop_words='english', ngram_range=(1,3), min_df=2`  | 0.65 | 0.65 | 0.62 |\n",
    "| `ngram_range=(1,3), min_df=10`                       | 0.66 | 0.66 | 0.64 |\n",
    "\n",
    "#### Comment évoluent les scores lorsqu'on ajoute un TfidfVectorizer ?\n",
    "\n",
    "| `...Vectorizer` | P    | R    | f1   |\n",
    "|-----------------|------|------|------|\n",
    "| `Count`         | 0.63 | 0.64 | 0.62 |\n",
    "| `Tfidf`         | 0.68 | 0.66 | 0.62 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763628bb-168d-4ae2-ab54-b2b748d90910",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36de46-6c9e-4cc1-ae40-dae4ae175831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "confusion = confusion_matrix(ground_truth_labels, submission_labels, labels=index2label)\n",
    "confusion_plot = ConfusionMatrixDisplay(confusion, display_labels=index2label)\n",
    "confusion_plot.plot(xticks_rotation=60)\n",
    "_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
