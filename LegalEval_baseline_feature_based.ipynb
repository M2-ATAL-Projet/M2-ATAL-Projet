{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4ae8f9",
      "metadata": {
        "id": "3c4ae8f9"
      },
      "outputs": [],
      "source": [
        "%pip install scikit-learn nltk numpy pandas spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2783b712-422b-43c7-9c3f-33e83d8511e9",
      "metadata": {
        "id": "2783b712-422b-43c7-9c3f-33e83d8511e9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "from joblib import parallel_backend\n",
        "from nltk.stem import LancasterStemmer, PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
        "from numpy import ndarray\n",
        "from pandas import DataFrame\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d14558d4",
      "metadata": {
        "id": "d14558d4"
      },
      "outputs": [],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "spacy_sm = spacy.load('en_core_web_sm')\n",
        "spacy_lg = spacy.load('en_core_web_lg')\n",
        "\n",
        "nlp = spacy_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "979a4ae3-919e-455a-827d-769c709bd74e",
      "metadata": {
        "id": "979a4ae3-919e-455a-827d-769c709bd74e"
      },
      "source": [
        "## Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b2f7e9e-3d9b-4033-be4f-17c59001bc42",
      "metadata": {
        "id": "4b2f7e9e-3d9b-4033-be4f-17c59001bc42"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('BUILD/train.csv')\n",
        "dev = pd.read_csv('BUILD/dev.csv')\n",
        "test = pd.read_csv('BUILD/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adff3a15-4b23-4aff-a26a-81502588afe0",
      "metadata": {
        "id": "adff3a15-4b23-4aff-a26a-81502588afe0"
      },
      "source": [
        "## Extraction des descripteurs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c32d1e-47df-48d8-955c-48178de7769c",
      "metadata": {
        "id": "09c32d1e-47df-48d8-955c-48178de7769c"
      },
      "source": [
        "Le ColumnTransformer permet de calculer des descripteurs simplement à partir d'un dataframe.\n",
        "Il s'agit d'une liste de 3 élements:\n",
        "- le nom du descripteur (str)\n",
        "- une fonction ou un objet scikit-learn qui implémente `fit` et ou `transform`\n",
        "- la colonne à utiliser\n",
        "\n",
        "Par exemple pour le descripteur `sentence_position`, on va utiliser la colonne `sentence_percent` directement (`passthrough`) (il faut utiliser des crochets pour que la taille du vecteur soit correcte)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f258c0c1-3048-4683-b46d-263e0810b6f4",
      "metadata": {
        "id": "f258c0c1-3048-4683-b46d-263e0810b6f4"
      },
      "outputs": [],
      "source": [
        "def sentence_position(df: DataFrame):\n",
        "    doc2nbsent = df.groupby('doc_id')['sentence_index'].max().to_dict()\n",
        "    df['nb_sent'] = df['doc_id'].map(doc2nbsent.get)\n",
        "    position = df['sentence_index'] / df['nb_sent']\n",
        "    return position.values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e966b8",
      "metadata": {
        "id": "d9e966b8"
      },
      "outputs": [],
      "source": [
        "def is_verb(tag: str):\n",
        "    return tag.startswith('VB') or tag == 'MD'\n",
        "\n",
        "def verb_tense(sentence: str):\n",
        "    verbs = [tag for _, tag in nltk.pos_tag(nltk.word_tokenize(sentence)) if is_verb(tag)]\n",
        "    return '' if len(verbs) == 0 else verbs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ac3b20a",
      "metadata": {
        "id": "1ac3b20a"
      },
      "outputs": [],
      "source": [
        "train['verb_tense'] = train['text'].map(verb_tense)\n",
        "dev['verb_tense'] = dev['text'].map(verb_tense)\n",
        "test['verb_tense'] = test['text'].map(verb_tense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a4b359",
      "metadata": {
        "id": "04a4b359"
      },
      "outputs": [],
      "source": [
        "verb_tense_encoding = ['VB', 'VBC', 'VBD', 'VBF', 'VBG', 'VBN', 'VBP', 'VBZ', 'MD']\n",
        "\n",
        "def verb_tense_encode(df: DataFrame):\n",
        "    return np.asarray([[1 if verb_tense_encoding[i] == vt else 0 for i in range(len(verb_tense_encoding))] for vt in df['verb_tense']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mqut_AwAdyDo",
      "metadata": {
        "id": "mqut_AwAdyDo"
      },
      "outputs": [],
      "source": [
        "train['doc'] = np.asarray(nlp.pipe(train['text']))\n",
        "dev['doc'] = np.asarray(nlp.pipe(dev['text']))\n",
        "test['doc'] = np.asarray(nlp.pipe(test['text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bnS7H6f5irQZ",
      "metadata": {
        "id": "bnS7H6f5irQZ"
      },
      "outputs": [],
      "source": [
        "def entity_count(entity_type: str):\n",
        "    return lambda df: np.asarray([[sum(1 for ent in doc.ents if ent.label_ == entity_type)] for doc in df['doc']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d026a897",
      "metadata": {
        "id": "d026a897"
      },
      "outputs": [],
      "source": [
        "def sentence_length(df: DataFrame):\n",
        "    \"\"\"Donne la longueur des phrases.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Corpus\n",
        "    \"\"\"\n",
        "    return df['text'].map(lambda x: len(x.split())).values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a526175-92b9-4c29-a40d-d731e4bec04f",
      "metadata": {
        "id": "1a526175-92b9-4c29-a40d-d731e4bec04f"
      },
      "outputs": [],
      "source": [
        "def contains_ldots(sentence: str):\n",
        "    return 1 if '...' in sentence else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86f13059-3037-4f21-a307-bc200f8e3ac6",
      "metadata": {
        "id": "86f13059-3037-4f21-a307-bc200f8e3ac6"
      },
      "outputs": [],
      "source": [
        "train['contains_ldots'] = train['text'].map(contains_ldots)\n",
        "dev['contains_ldots'] = dev['text'].map(contains_ldots)\n",
        "test['contains_ldots'] = test['text'].map(contains_ldots)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32d28f5d",
      "metadata": {
        "id": "32d28f5d"
      },
      "outputs": [],
      "source": [
        "#stemmer = LancasterStemmer()\n",
        "#stemmer = PorterStemmer()\n",
        "#stemmer = SnowballStemmer(language='english')\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super().build_analyzer()\n",
        "        return lambda doc: [stemmer.lemmatize(w) for w in analyzer(doc)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f57e99cd",
      "metadata": {
        "id": "f57e99cd"
      },
      "outputs": [],
      "source": [
        "class LemmatizedTfidfVectorizer(TfidfVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        #return lambda doc: [w.text for w in doc]\n",
        "        return lambda doc: [w.lemma_ for w in doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc185f73",
      "metadata": {
        "id": "cc185f73"
      },
      "outputs": [],
      "source": [
        "class PosTfidfVectorizer(TfidfVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super().build_analyzer()\n",
        "        return lambda doc: [w + '/' + tag for w, tag in nltk.pos_tag(analyzer(doc))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10cc1730-c5d3-4471-b2e9-865db82ded17",
      "metadata": {
        "id": "10cc1730-c5d3-4471-b2e9-865db82ded17"
      },
      "outputs": [],
      "source": [
        "classifier = make_pipeline(\n",
        "    make_column_transformer(\n",
        "        (\n",
        "            TfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=10),\n",
        "            'text'\n",
        "        ),\n",
        "        # ==> n'améliore pas\n",
        "        #(\n",
        "        #    StemmedTfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=10),\n",
        "        #    'text'\n",
        "        #),\n",
        "        (\n",
        "            LemmatizedTfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=10),\n",
        "            'doc'\n",
        "        ),\n",
        "        # ==> n'améliore pas\n",
        "        #(\n",
        "        #    PosTfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=10),\n",
        "        #    'text'\n",
        "        #),\n",
        "        # ==> n'améliore pas\n",
        "        #(\n",
        "        #    'passthrough',\n",
        "        #    ['sentence_index']\n",
        "        #),\n",
        "        (\n",
        "            'passthrough',\n",
        "            ['contains_ldots']\n",
        "        ),\n",
        "        (\n",
        "            FunctionTransformer(sentence_position),\n",
        "            ['doc_id', 'sentence_index']\n",
        "        ),\n",
        "        # ==> MDR\n",
        "        #(\n",
        "        #    FunctionTransformer(entity_count('LOC')),\n",
        "        #    ['doc']\n",
        "        #),\n",
        "        (\n",
        "            FunctionTransformer(entity_count('LAW')),\n",
        "            ['doc']\n",
        "        ),\n",
        "        (\n",
        "            FunctionTransformer(entity_count('DATE')),\n",
        "            ['doc']\n",
        "        ),\n",
        "        # ==> n'améliore pas\n",
        "        #(\n",
        "        #    FunctionTransformer(entity_count('PERSON')),\n",
        "        #    ['doc']\n",
        "        #),\n",
        "        (\n",
        "            FunctionTransformer(verb_tense_encode),\n",
        "            ['verb_tense']\n",
        "        ),\n",
        "        (\n",
        "            FunctionTransformer(sentence_length),\n",
        "            ['text']\n",
        "        ),\n",
        "    ),\n",
        "    LogisticRegression(multi_class='multinomial', max_iter=10000)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c228838-b817-4a64-8fd4-21c0f01f0f4f",
      "metadata": {
        "id": "4c228838-b817-4a64-8fd4-21c0f01f0f4f"
      },
      "source": [
        "## Entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85527abe-b1dc-4feb-9488-4cecd0140049",
      "metadata": {
        "id": "85527abe-b1dc-4feb-9488-4cecd0140049"
      },
      "outputs": [],
      "source": [
        "# On entraîne le modèle sur les 100 premiers exemples.\n",
        "with parallel_backend('threading', n_jobs=4):\n",
        "    classifier.fit(train, train['labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80370160-4093-458a-ac11-0fc2f29cae89",
      "metadata": {
        "id": "80370160-4093-458a-ac11-0fc2f29cae89"
      },
      "source": [
        "## Prédiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51a23dbf-e639-462c-bf45-dbba06be5c59",
      "metadata": {
        "id": "51a23dbf-e639-462c-bf45-dbba06be5c59"
      },
      "outputs": [],
      "source": [
        "# Prédit puis choisis l'étiquette qui a la plus haut probabilité\n",
        "train['pred'] = classifier.predict(train)\n",
        "dev['pred'] = classifier.predict(dev)\n",
        "test['pred'] = classifier.predict(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9faa92-524e-45c0-9c26-32b5d0187db2",
      "metadata": {
        "id": "8c9faa92-524e-45c0-9c26-32b5d0187db2"
      },
      "outputs": [],
      "source": [
        "# Pour obtenir le nom des étiquettes prédites\n",
        "# On récupère le nom et l'ordre des étiquettes\n",
        "index2label: ndarray = classifier.named_steps['logisticregression'].classes_\n",
        "\n",
        "# Retourne la probabilité pour chacune des étiquettes\n",
        "predictions_prob = classifier.predict_proba(dev.iloc[:10])\n",
        "# On choisis l'étiquette avec la plus haute probabilité\n",
        "index_max_predictions = predictions_prob.argmax(axis=1).tolist()\n",
        "\n",
        "# Ces deux liste devraient être les mêmes\n",
        "print([index2label[l] for l in index_max_predictions])\n",
        "print(classifier.predict(dev.iloc[:10]).tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fd3bd76-c5f6-4bf5-b269-f19429c91730",
      "metadata": {
        "id": "5fd3bd76-c5f6-4bf5-b269-f19429c91730"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_pK9K15smg0L",
      "metadata": {
        "id": "_pK9K15smg0L"
      },
      "outputs": [],
      "source": [
        "def eval(df: DataFrame):\n",
        "    ground_truth_labels = df['labels']\n",
        "    submission_labels = df['pred']\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        ground_truth_labels, submission_labels, average='weighted'\n",
        "    )\n",
        "    # https://pyformat.info/#number\n",
        "    print(f'{precision:.3f} & {recall:.3f} & {f1:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57aca284-4c7c-4fdf-89dd-5f4b2c520e8c",
      "metadata": {
        "id": "57aca284-4c7c-4fdf-89dd-5f4b2c520e8c"
      },
      "source": [
        "### Erreur d'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e90ab6-d408-4143-9eec-972e648c8d22",
      "metadata": {
        "id": "49e90ab6-d408-4143-9eec-972e648c8d22"
      },
      "outputs": [],
      "source": [
        "eval(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de33fab1-93d8-4f47-8d1e-f11eb5548c7b",
      "metadata": {
        "id": "de33fab1-93d8-4f47-8d1e-f11eb5548c7b"
      },
      "source": [
        "### Erreur de validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8d31c0-4603-4580-96a5-b8edbabad1e2",
      "metadata": {
        "id": "ce8d31c0-4603-4580-96a5-b8edbabad1e2"
      },
      "outputs": [],
      "source": [
        "eval(dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c01d4825",
      "metadata": {
        "id": "c01d4825"
      },
      "source": [
        "#### Comment évoluent les scores lorsqu'on enlève un descripteur ?\n",
        "\n",
        "| CV | SV | SP | P    | R    | f1   |\n",
        "|----|----|----|------|------|------|\n",
        "| x  | x  | x  | 0.63 | 0.64 | 0.62 |\n",
        "| x  |    | x  | 0.63 | 0.64 | 0.61 |\n",
        "| x  | x  |    | 0.54 | 0.54 | 0.52 |\n",
        "| x  |    |    | 0.54 | 0.54 | 0.52 |\n",
        "|    | x  | x  | 0.38 | 0.54 | 0.44 |\n",
        "|    |    | x  | 0.38 | 0.53 | 0.43 |\n",
        "|    | x  |    | 0.21 | 0.34 | 0.19 |\n",
        "\n",
        "__Observations :__\n",
        "\n",
        "* Les colonnes du *count-vectorizer* (CV) ont le plus d'impact sur le modèle.\n",
        "* La colonne de *single-values* (SV) n'a qu'un très faible impact sur le modèle.\n",
        "\n",
        "#### Comment évoluent les scores lorsqu'on change les paramètres du CountVectorizer ?\n",
        "\n",
        "| `CountVectorizer(...)`                               | P    | R    | f1   |\n",
        "|------------------------------------------------------|------|------|------|\n",
        "| `stop_words='english', ngram_range=(1,3), min_df=10` | 0.63 | 0.64 | 0.62 |\n",
        "| `stop_words='english', ngram_range=(1,8), min_df=10` | 0.64 | 0.64 | 0.62 |\n",
        "| `stop_words='english', ngram_range=(1,3), min_df=2`  | 0.65 | 0.65 | 0.62 |\n",
        "| `ngram_range=(1,3), min_df=10`                       | 0.66 | 0.66 | 0.64 |\n",
        "\n",
        "#### Comment évoluent les scores lorsqu'on ajoute un TfidfVectorizer ?\n",
        "\n",
        "| `...Vectorizer` | P    | R    | f1   |\n",
        "|-----------------|------|------|------|\n",
        "| `Count`         | 0.63 | 0.64 | 0.62 |\n",
        "| `Tfidf`         | 0.68 | 0.66 | 0.62 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "763628bb-168d-4ae2-ab54-b2b748d90910",
      "metadata": {
        "id": "763628bb-168d-4ae2-ab54-b2b748d90910"
      },
      "source": [
        "### Matrice de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab36de46-6c9e-4cc1-ae40-dae4ae175831",
      "metadata": {
        "id": "ab36de46-6c9e-4cc1-ae40-dae4ae175831"
      },
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "confusion = confusion_matrix(dev['labels'], dev['pred'], labels=index2label)\n",
        "confusion_plot = ConfusionMatrixDisplay(confusion, display_labels=index2label)\n",
        "confusion_plot.plot(xticks_rotation=60)\n",
        "_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b021225",
      "metadata": {},
      "outputs": [],
      "source": [
        "dev[['annotation_id', 'pred']].rename(columns={'pred': 'labels'}).to_csv('run1_dev.csv', index=False)\n",
        "test[['annotation_id', 'pred']].rename(columns={'pred': 'labels'}).to_csv('run1_test.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
